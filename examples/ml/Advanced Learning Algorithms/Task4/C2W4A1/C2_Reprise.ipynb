{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0778a2c-d15b-4a14-ae68-b442aa3b86d3",
   "metadata": {},
   "source": [
    "# Labo pratique : Arbres de décision\n",
    "\n",
    "Dans cet exercice, vous allez implémenter un arbre de décision à partir de zéro et l'appliquer à la tâche de classification d'un champignon pour savoir s'il est comestible ou vénéneux.\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 -  Problem Statement](#2)\n",
    "- [ 3 - Dataset](#3)\n",
    "  - [ 3.1 One hot encoded dataset](#3.1)\n",
    "- [ 4 - Decision Tree Refresher](#4)\n",
    "  - [ 4.1  Calculate entropy](#4.1)\n",
    "    - [ Exercise 1](#ex01)\n",
    "  - [ 4.2  Split dataset](#4.2)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 4.3  Calculate information gain](#4.3)\n",
    "    - [ Exercise 3](#ex03)\n",
    "  - [ 4.4  Get best split](#4.4)\n",
    "    - [ Exercise 4](#ex04)\n",
    "- [ 5 - Building the tree](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e3a05-ac83-4954-a160-3d345db39359",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages \n",
    "\n",
    "Tout d'abord, exécutons la cellule ci-dessous pour importer tous les paquets dont vous aurez besoin au cours de ce travail.\n",
    "- [numpy](https://www.numpy.org) est le paquetage fondamental pour travailler avec des matrices en Python.\n",
    "- [matplotlib](https://matplotlib.org) est une bibliothèque célèbre pour tracer des graphiques en Python.\n",
    "- ``utils.py`` contient des fonctions d'aide pour ce travail. Vous n'avez pas besoin de modifier le code de ce fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae084321-07d4-4b52-8ae9-98ee63a676a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccbb31-dbe5-4543-a41c-167da0a002e5",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Énoncé du problème\n",
    "\n",
    "Supposons que vous créiez une entreprise qui cultive et vend des champignons sauvages. \n",
    "- Comme tous les champignons ne sont pas comestibles, vous aimeriez pouvoir déterminer si un champignon donné est comestible ou vénéneux sur la base de ses caractéristiques physiques\n",
    "- Vous disposez de données existantes que vous pouvez utiliser pour cette tâche. \n",
    "\n",
    "Pouvez-vous utiliser ces données pour vous aider à identifier les champignons qui peuvent être vendus en toute sécurité ? \n",
    "\n",
    "Remarque : l'ensemble de données utilisé ne l'est qu'à des fins d'illustration. Il ne s'agit pas d'un guide d'identification des champignons comestibles.\n",
    "\n",
    "- Vous disposez de 10 exemples de champignons. Pour chaque exemple, vous disposez de\n",
    "    - Trois caractéristiques\n",
    "        - Couleur du chapeau (`Brun` ou `Red`),\n",
    "        - Forme du pied (`Tapissement` ou `Agrandissement`), et\n",
    "        - Solitaire (`Oui` ou `Non`)\n",
    "    - Étiquette\n",
    "        - Comestible (`1` indiquant oui ou `0` indiquant toxique)\n",
    "\n",
    "\n",
    "<a name=\"3\"></a>\n",
    "## 3 - Dataset\n",
    "\n",
    "Vous commencerez par charger l'ensemble de données pour cette tâche. L'ensemble de données que vous avez collecté est le suivant :\n",
    "\n",
    "\n",
    "3.1 Ensemble de données codées à chaud\n",
    "Pour faciliter la mise en œuvre, nous avons codé les caractéristiques à chaud (nous les avons transformées en caractéristiques à valeur 0 ou 1).\n",
    "\n",
    "| Cap Color | Stalk Shape | Solitary | Edible |\n",
    "|:---------:|:-----------:|:--------:|:------:|\n",
    "|   Brown   |   Tapering  |    Yes   |    1   |\n",
    "|   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |   Tapering  |    Yes   |    1   |\n",
    "|    Red    |   Tapering  |    Yes   |    0   |\n",
    "|    Red    |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "|    Red    |   Tapering  |    No    |    1   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "\n",
    "Par conséquent, `X_train` contient trois caractéristiques pour chaque exemple,\n",
    "- `X_train` contient trois caractéristiques pour chaque exemple \n",
    "    - Couleur brune (une valeur de `1` indique une couleur de chapeau \"brune\" et `0` indique une couleur de chapeau \"rouge\")\n",
    "    - Forme effilée (une valeur de `1` indique une forme de tige effilée et une valeur de `0` indique une forme de tige élargie)\n",
    "    - Solitaire (Une valeur de `1` indique \"Oui\" et `0` indique \"Non\")\n",
    "\n",
    "- `y_train` indique si le champignon est comestible \n",
    "    - `y = 1` indique qu'il est comestible\n",
    "    - `y = 0` indique qu'il est toxique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720599f7-6eee-4677-be85-04d4979c7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038995f6-294a-4506-b216-6b87e70d78d1",
   "metadata": {},
   "source": [
    "#### Afficher les variables\n",
    "Familiarisez-vous avec votre ensemble de données.  \n",
    "- Un bon point de départ est d'imprimer chaque variable et de voir ce qu'elle contient.\n",
    "\n",
    "Le code ci-dessous affiche les premiers éléments de `X_train` et le type de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b02b33d-3d66-4955-a5d8-e42cc563b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of X_train:\n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of X_train:\\n\", X_train[:5])\n",
    "print(\"Type of X_train:\",type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48231d-14b5-42f9-98f6-94e9348e01f0",
   "metadata": {},
   "source": [
    "Maintenant, faisons la même chose pour `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d02d08-d1b5-478e-958a-f595e4c2241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of y_train: [1 1 0 0 1]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of y_train:\", y_train[:5])\n",
    "print(\"Type of y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7865c05-108b-4134-aa42-fb066cc7a4cb",
   "metadata": {},
   "source": [
    "#### Vérifiez les dimensions de vos variables\n",
    "\n",
    "Une autre façon utile de se familiariser avec vos données est de visualiser leurs dimensions.\n",
    "\n",
    "Veuillez imprimer la forme de `X_train` et `y_train` et voir combien d'exemples de formation vous avez dans votre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39acc746-7036-4aec-976d-2161b6e5ee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (10, 3)\n",
      "The shape of y_train is:  (10,)\n",
      "Number of training examples (m): 10\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X_train is:', X_train.shape)\n",
    "print ('The shape of y_train is: ', y_train.shape)\n",
    "print ('Number of training examples (m):', len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328dbe45-12c7-417f-b978-c6671bc91a47",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Remise à niveau sur les arbres de décision\n",
    "\n",
    "Dans ce TP, vous allez construire un arbre de décision basé sur le jeu de données fourni.\n",
    "\n",
    "- Rappelons que les étapes de construction d'un arbre de décision sont les suivantes :\n",
    "    - Commencer avec tous les exemples au nœud racine\n",
    "    - Calculer le gain d'information pour la division sur toutes les caractéristiques possibles, et choisir celle qui présente le gain d'information le plus élevé.\n",
    "    - Diviser l'ensemble de données en fonction de la caractéristique sélectionnée et créer les branches gauche et droite de l'arbre.\n",
    "    - Répéter le processus de fractionnement jusqu'à ce que les critères d'arrêt soient remplis.\n",
    "  \n",
    "  \n",
    "- Dans ce laboratoire, vous mettrez en œuvre les fonctions suivantes, qui vous permettront de diviser un nœud en branches gauche et droite à l'aide de la caractéristique présentant le gain d'information le plus élevé\n",
    "    - Calculer l'entropie au niveau d'un noeud \n",
    "    - Diviser l'ensemble de données au niveau d'un noeud en branches gauche et droite sur la base d'une caractéristique donnée\n",
    "    - Calculer le gain d'information résultant de la division sur la base d'une caractéristique donnée\n",
    "    - Choisir la caractéristique qui maximise le gain d'information\n",
    "    \n",
    "- Nous utiliserons ensuite les fonctions d'aide que vous avez implémentées pour construire un arbre de décision en répétant le processus de division jusqu'à ce que le critère d'arrêt soit satisfait. \n",
    "    - Pour ce laboratoire, le critère d'arrêt que nous avons choisi est la définition d'une profondeur maximale de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1360c-1f88-4bb2-8ddf-06c088d476a5",
   "metadata": {},
   "source": [
    "<a name=\"4.1\"></a>\n",
    "### 4.1  Calculer l'entropie\n",
    "\n",
    "Tout d'abord, vous allez écrire une fonction d'aide appelée `compute_entropy` qui calcule l'entropie (mesure de l'impureté) d'un noeud. \n",
    "- La fonction prend un tableau numpy (`y`) qui indique si les exemples de ce nœud sont comestibles (`1`) ou toxiques (`0`). \n",
    "\n",
    "Complétez la fonction `compute_entropy()` ci-dessous pour :\n",
    "* Calculer $p_1$, qui est la fraction d'exemples qui sont comestibles (c'est-à-dire qui ont une valeur = `1` dans `y`).\n",
    "* L'entropie est alors calculée comme suit \n",
    "\n",
    "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1) \\text{log}_2(1- p_1)$$\n",
    "* Note \n",
    "    * The log is calculated with base $2$\n",
    "    * For implementation purposes, $0\\text{log}_2(0) = 0$. That is, if `p_1 = 0` or `p_1 = 1`, set the entropy to `0`\n",
    "    * Make sure to check that the data at a node is not empty (i.e. `len(y) != 0`). Return `0` if it is\n",
    "    \n",
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "Veuillez compléter la fonction `compute_entropy()` en utilisant les instructions précédentes.\n",
    "    \n",
    "Si vous êtes bloqué, vous pouvez consulter les conseils présentés après la cellule ci-dessous pour vous aider dans l'implémentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5dcf371-6c96-4078-93d1-f81f149624d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: compute_entropy\n",
    "\n",
    "def compute_entropy(y):\n",
    "    \"\"\"\n",
    "    Computes the entropy for \n",
    "    \n",
    "    Args:\n",
    "       y (ndarray): Numpy array indicating whether each example at a node is\n",
    "           edible (`1`) or poisonous (`0`)\n",
    "       \n",
    "    Returns:\n",
    "        entropy (float): Entropy at that node\n",
    "        \n",
    "    \"\"\"\n",
    "    # You need to return the following variables correctly\n",
    "    entropy = 0.\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    if len(y) != 0:\n",
    "        p1 = p1 = len(y[y == 1]) / len(y) \n",
    "     # For p1 = 0 and 1, set the entropy to 0 (to handle 0log0)\n",
    "        if p1 != 0 and p1 != 1:\n",
    "             entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1)\n",
    "        else:\n",
    "             entropy = 0\n",
    "    ### END CODE HERE ###        \n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a1381-51c3-4123-9847-4862f6337ad2",
   "metadata": {},
   "source": [
    "Vous pouvez vérifier si votre mise en œuvre est correcte en exécutant le code de test suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c08386c-424d-4acd-8e6a-0a36d733162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy at root node:  1.0\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Compute entropy at the root node (i.e. with all examples)\n",
    "# Since we have 5 edible and 5 non-edible mushrooms, the entropy should be 1\"\n",
    "\n",
    "print(\"Entropy at root node: \", compute_entropy(y_train)) \n",
    "\n",
    "# UNIT TESTS\n",
    "compute_entropy_test(compute_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed0b37-4659-4337-aac2-8e6d674f0036",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Entropy at root node:<b> 1.0 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915d04-2d26-49b0-85ff-bea0cd671e38",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### 4.2  Diviser le jeu de données\n",
    "\n",
    "Ensuite, vous écrirez une fonction d'aide appelée `split_dataset` qui prend les données à un noeud et une caractéristique à diviser et la divise en branches gauche et droite. Plus tard dans le labo, vous implémenterez un code pour calculer la qualité de la division.\n",
    "\n",
    "- La fonction prend en charge les données d'apprentissage, la liste des indices des points de données à ce noeud, ainsi que la caractéristique à diviser. \n",
    "- Elle divise les données et renvoie le sous-ensemble d'indices à la branche gauche et à la branche droite.\n",
    "- Par exemple, disons que nous commençons au noeud racine (donc `node_indices = [0,1,2,3,4,5,6,7,8,9]`), et que nous choisissons de diviser sur la caractéristique `0`, qui est de savoir si l'exemple a une casquette marron ou non.\n",
    "    - La sortie de la fonction est donc `indices_gauche = [0,1,2,3,4,7,9]` et `indices_droite = [5,6,8]`\n",
    "    \n",
    "| Index | Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
    "|:-----:|:---------:|:--------------------:|:--------:|:------:|\n",
    "|   0   |     1     |           1          |     1    |    1   |\n",
    "|   1   |     1     |           0          |     1    |    1   |\n",
    "|   2   |     1     |           0          |     0    |    0   |\n",
    "|   3   |     1     |           0          |     0    |    0   |\n",
    "|   4   |     1     |           1          |     1    |    1   |\n",
    "|   5   |     0     |           1          |     1    |    0   |\n",
    "|   6   |     0     |           0          |     0    |    0   |\n",
    "|   7   |     1     |           0          |     1    |    1   |\n",
    "|   8   |     0     |           1          |     0    |    1   |\n",
    "|   9   |     1     |           0          |     0    |    0   |\n",
    "\n",
    "<a name=\"ex02\"></a>\n",
    "### Exercise 2\n",
    "\n",
    "Veuillez compléter la fonction `split_dataset()` présentée ci-dessous\n",
    "\n",
    "- Pour chaque index dans `node_indices`\n",
    "    - Si la valeur de `X` à cet index pour cet élément est `1`, ajoutez l'index à `left_indices`\n",
    "    - Si la valeur de `X` à cet index pour cet élément est `0`, ajoutez l'index à `right_indices`\n",
    "\n",
    "Si vous êtes bloqué, vous pouvez consulter les conseils présentés après la cellule ci-dessous pour vous aider dans l'implémentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6901262-1af3-4a52-85f1-c1fde0a0cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: split_dataset\n",
    "\n",
    "def split_dataset(X, node_indices, feature):\n",
    "    \"\"\"\n",
    "    Splits the data at the given node into\n",
    "    left and right branches\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):             Data matrix of shape(n_samples, n_features)\n",
    "        node_indices (list):  List containing the active indices. I.e, the samples being considered at this step.\n",
    "        feature (int):           Index of feature to split on\n",
    "    \n",
    "    Returns:\n",
    "        left_indices (list): Indices with feature value == 1\n",
    "        right_indices (list): Indices with feature value == 0\n",
    "    \"\"\"\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for i in node_indices:   \n",
    "        if X[i][feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    return left_indices, right_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66478d33-961b-4960-8d42-195ad6c649e9",
   "metadata": {},
   "source": [
    "Vérifions maintenant votre mise en œuvre à l'aide des blocs de code ci-dessous. Essayons de diviser l'ensemble de données au niveau du nœud racine, qui contient tous les exemples de la caractéristique 0 (casquette brune), comme nous l'avons vu plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a87e14-2fec-41aa-babf-084bd324b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left indices:  [0, 1, 2, 3, 4, 7, 9]\n",
      "Right indices:  [5, 6, 8]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Feel free to play around with these variables\n",
    "# The dataset only has three features, so this value can be 0 (Brown Cap), 1 (Tapering Stalk Shape) or 2 (Solitary)\n",
    "feature = 0\n",
    "\n",
    "left_indices, right_indices = split_dataset(X_train, root_indices, feature)\n",
    "\n",
    "print(\"Left indices: \", left_indices)\n",
    "print(\"Right indices: \", right_indices)\n",
    "\n",
    "# UNIT TESTS    \n",
    "split_dataset_test(split_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e102439d-3e13-4c20-9966-295dfc304e1c",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "```\n",
    "Left indices:  [0, 1, 2, 3, 4, 7, 9]\n",
    "Right indices:  [5, 6, 8]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bfc8df-c224-42d5-b6ab-ec802d42076b",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3  Calculer le gain d'information\n",
    "\n",
    "Ensuite, vous écrirez une fonction appelée `information_gain` qui prend les données d'apprentissage, les indices d'un noeud et une caractéristique à diviser et renvoie le gain d'information de la division.\n",
    "\n",
    "<a name=\"ex03\"></a>\n",
    "### Exercise 3\n",
    "\n",
    "Veuillez compléter la fonction `compute_information_gain()` présentée ci-dessous pour calculer\n",
    "\n",
    "$$\\text{Information Gain} = H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$\n",
    "\n",
    "où \n",
    "- $H(p_1^\\text{node})$ est l'entropie au niveau du nœud \n",
    "- $H(p_1^\\text{gauche})$ et $H(p_1^\\text{droite})$ sont les entropies des branches gauche et droite résultant de la scission\n",
    "- $w^{\\text{left}}$ et $w^{\\text{right}}$ sont les proportions d'exemples dans les branches gauche et droite, respectivement.\n",
    "\n",
    "Remarque :\n",
    "- Vous pouvez utiliser la fonction `compute_entropy()` que vous avez implémentée ci-dessus pour calculer l'entropie.\n",
    "- Nous avons fourni un code de démarrage qui utilise la fonction `split_dataset()` que vous avez implémentée ci-dessus pour diviser l'ensemble de données. \n",
    "\n",
    "Si vous êtes bloqué, vous pouvez consulter les conseils présentés après la cellule ci-dessous pour vous aider dans l'implémentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d4b393-56b2-4081-a2c4-7021068b9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_information_gain\n",
    "\n",
    "def compute_information_gain(X, y, node_indices, feature):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the information of splitting the node on a given feature\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "   \n",
    "    Returns:\n",
    "        cost (float):        Cost computed\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Split dataset\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
    "    \n",
    "    # Some useful variables\n",
    "    X_node, y_node = X[node_indices], y[node_indices]\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[right_indices], y[right_indices]\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    information_gain = 0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    node_entropy = compute_entropy(y_node)\n",
    "    left_entropy = compute_entropy(y_left)\n",
    "    right_entropy = compute_entropy(y_right)\n",
    "    \n",
    "    # Weights \n",
    "    w_left = len(X_left) / len(X_node)\n",
    "    w_right = len(X_right) / len(X_node)\n",
    "    \n",
    "    #Weighted entropy\n",
    "    weighted_entropy = w_left * left_entropy + w_right * right_entropy\n",
    "    \n",
    "    #Information gain \n",
    "    information_gain = node_entropy - weighted_entropy\n",
    "    \n",
    "    ### END CODE HERE ###  \n",
    "    \n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afffb6e-327e-4969-89ad-04761e950220",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant vérifier votre mise en œuvre à l'aide de la cellule ci-dessous et calculer le gain d'information qu'apporterait une répartition sur chacune des caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "584fdc20-1c39-482e-91c9-3ec641a157c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain from splitting the root on brown cap:  0.034851554559677034\n",
      "Information Gain from splitting the root on tapering stalk shape:  0.12451124978365313\n",
      "Information Gain from splitting the root on solitary:  0.2780719051126377\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "info_gain0 = compute_information_gain(X_train, y_train, root_indices, feature=0)\n",
    "print(\"Information Gain from splitting the root on brown cap: \", info_gain0)\n",
    "    \n",
    "info_gain1 = compute_information_gain(X_train, y_train, root_indices, feature=1)\n",
    "print(\"Information Gain from splitting the root on tapering stalk shape: \", info_gain1)\n",
    "\n",
    "info_gain2 = compute_information_gain(X_train, y_train, root_indices, feature=2)\n",
    "print(\"Information Gain from splitting the root on solitary: \", info_gain2)\n",
    "\n",
    "# UNIT TESTS\n",
    "compute_information_gain_test(compute_information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ca349b-0365-4afd-9fec-83f7cbc51275",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "```\n",
    "Informations obtenues en divisant la racine sur le chapeau brun :  0.034851554559677034\n",
    "Gain d'information de la division de la racine sur la forme effilée de la tige : 0.12451124978365313\n",
    "Gain d'information lié à la division de la racine sur la forme solitaire :  0.2780719051126377\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c22841-b4eb-43b1-9943-297ac05754f2",
   "metadata": {},
   "source": [
    "Le fractionnement sur \"Solitaire\" (caractéristique = 2) au nœud racine donne le gain d'information maximal. Il s'agit donc de la meilleure caractéristique sur laquelle effectuer le découpage au niveau du nœud racine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bd4e2-75a4-4856-b187-ab9cd91c69cf",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"></a>\n",
    "### 4.4  Obtenir la meilleure répartition\n",
    "Ecrivons maintenant une fonction pour obtenir la meilleure caractéristique à diviser en calculant le gain d'information de chaque caractéristique comme nous l'avons fait ci-dessus et en renvoyant la caractéristique qui donne le gain d'information maximal.\n",
    "\n",
    "<a name=\"ex04\"></a>\n",
    "### Exercise 4\n",
    "Veuillez compléter la fonction `get_best_split()` présentée ci-dessous.\n",
    "- La fonction prend en compte les données d'apprentissage, ainsi que les indices des points de données à ce noeud\n",
    "- La sortie de la fonction est la caractéristique qui donne le gain d'information maximal. \n",
    "    - Vous pouvez utiliser la fonction `compute_information_gain()` pour itérer à travers les caractéristiques et calculer l'information pour chaque caractéristique.\n",
    "Si vous êtes bloqué, vous pouvez consulter les conseils présentés après la cellule ci-dessous pour vous aider dans la mise en œuvre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f19bb04-20e5-4c9f-8966-8e47b1c27eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: get_best_split\n",
    "\n",
    "def get_best_split(X, y, node_indices):   \n",
    "    \"\"\"\n",
    "    Returns the optimal feature and threshold value\n",
    "    to split the node data \n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "\n",
    "    Returns:\n",
    "        best_feature (int):     The index of the best feature to split\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Some useful variables\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    best_feature = -1\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    max_info_gain=0\n",
    "    for feature in range(num_features):\n",
    "        info_gain = compute_information_gain(X, y, node_indices, feature)\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "                \n",
    "        \n",
    "    ### END CODE HERE ##    \n",
    "       \n",
    "    return best_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfca2e-894b-4864-9b1f-4b2a43e30ddc",
   "metadata": {},
   "source": [
    "Maintenant, vérifions la mise en œuvre de votre fonction à l'aide de la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ca0bc2-ca7b-4d4c-99d1-d8fa35ff452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature to split on: 2\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "best_feature = get_best_split(X_train, y_train, root_indices)\n",
    "print(\"Best feature to split on: %d\" % best_feature)\n",
    "\n",
    "# UNIT TESTS\n",
    "get_best_split_test(get_best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5c0da-45ea-493c-aab2-0abccd6c5fb8",
   "metadata": {},
   "source": [
    "Comme nous l'avons vu plus haut, la fonction renvoie que la meilleure caractéristique à scinder au nœud racine est la caractéristique 2 (\"Solitaire\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7787f-618c-41a2-95e4-08127a3464d0",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Construction de l'arbre\n",
    "\n",
    "Dans cette section, nous utilisons les fonctions que vous avez mises en œuvre ci-dessus pour générer un arbre de décision en choisissant successivement la meilleure caractéristique à scinder jusqu'à ce que nous atteignions le critère d'arrêt (la profondeur maximale est de 2).\n",
    "\n",
    "Vous n'avez pas besoin d'implémenter quoi que ce soit pour cette partie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa2fd1d-d150-4ee7-98cf-74f3a6760631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not graded\n",
    "tree = []\n",
    "\n",
    "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
    "    \"\"\"\n",
    "    Build a tree using the recursive algorithm that split the dataset into 2 subgroups at each node.\n",
    "    This function just prints the tree.\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "        branch_name (string):   Name of the branch. ['Root', 'Left', 'Right']\n",
    "        max_depth (int):        Max depth of the resulting tree. \n",
    "        current_depth (int):    Current depth. Parameter used during recursive call.\n",
    "   \n",
    "    \"\"\" \n",
    "\n",
    "    # Maximum depth reached - stop splitting\n",
    "    if current_depth == max_depth:\n",
    "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
    "        print(formatting, \"%s leaf node with indices\" % branch_name, node_indices)\n",
    "        return\n",
    "   \n",
    "    # Otherwise, get best split and split the data\n",
    "    # Get the best feature and threshold at this node\n",
    "    best_feature = get_best_split(X, y, node_indices) \n",
    "    tree.append((current_depth, branch_name, best_feature, node_indices))\n",
    "    \n",
    "    formatting = \"-\"*current_depth\n",
    "    print(\"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature))\n",
    "    \n",
    "    # Split the dataset at the best feature\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
    "    \n",
    "    # continue splitting the left and the right child. Increment current depth\n",
    "    build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1)\n",
    "    build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7ab475-aeb4-443c-abbc-de1b9e5be682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depth 0, Root: Split on feature: 2\n",
      "- Depth 1, Left: Split on feature: 0\n",
      "  -- Left leaf node with indices [0, 1, 4, 7]\n",
      "  -- Right leaf node with indices [5]\n",
      "- Depth 1, Right: Split on feature: 1\n",
      "  -- Left leaf node with indices [8]\n",
      "  -- Right leaf node with indices [2, 3, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42df321-a25b-472e-8bff-c900b543aa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
